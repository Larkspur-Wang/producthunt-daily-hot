import os
# from dotenv import load_dotenv
import requests
from datetime import datetime, timedelta, timezone
from bs4 import BeautifulSoup
import pytz
import time
import random
import json
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from typing import Optional, List, Dict, Any

# åŠ è½½ .env æ–‡ä»¶
# load_dotenv()

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"

producthunt_client_id = os.getenv('PRODUCTHUNT_CLIENT_ID')
producthunt_client_secret = os.getenv('PRODUCTHUNT_CLIENT_SECRET')

def call_gemini_api(prompt: str, model: str = "gemini-2.0-flash-exp", temperature: float = 0.8) -> str:
    """è°ƒç”¨Google Gemini API"""
    print(f"\n[DEBUG] æ­£åœ¨è°ƒç”¨Gemini APIï¼Œæ¨¡å‹ï¼š{model}")
    try:
        if not GOOGLE_API_KEY:
            raise ValueError("GOOGLE_API_KEY not found in environment variables")
            
        url = f"{GEMINI_API_BASE}/{model}:generateContent?key={GOOGLE_API_KEY}"
        headers = {'Content-Type': 'application/json'}
        
        data = {
            "contents": [{
                "parts":[{"text": prompt}]
            }],
            "generationConfig": {
                "temperature": temperature,
                "topK": 40,
                "topP": 0.95,
            }
        }
        
        print(f"[DEBUG] å‘é€APIè¯·æ±‚...")
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'candidates' in result and len(result['candidates']) > 0:
            print(f"[DEBUG] APIè°ƒç”¨æˆåŠŸ")
            return result['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            print(f"[DEBUG] APIè¿”å›ç»“æœä¸ºç©º")
            return ""
    except Exception as e:
        print(f"[DEBUG] APIè°ƒç”¨é”™è¯¯: {e}")
        return ""

class Product:
    def __init__(self, id: str, name: str, tagline: str, description: str, votesCount: int, createdAt: str, featuredAt: str, website: str, url: str, **kwargs):
        print(f"\n[DEBUG] æ­£åœ¨åˆå§‹åŒ–äº§å“: {name}")
        self.name = name
        self.tagline = tagline
        self.description = description
        self.votes_count = votesCount
        self.created_at = self.convert_to_beijing_time(createdAt)
        self.featured = "æ˜¯" if featuredAt else "å¦"
        self.website = website
        self.url = url
        
        print(f"[DEBUG] è·å–äº§å“å›¾ç‰‡URL...")
        self.og_image_url = self.fetch_og_image_url()
        
        print(f"[DEBUG] ç”Ÿæˆäº§å“å…³é”®è¯...")
        self.keyword = self.generate_keywords()
        
        print(f"[DEBUG] ç¿»è¯‘äº§å“æ ‡è¯­...")
        self.translated_tagline = self.translate_text(self.tagline)
        
        print(f"[DEBUG] ç¿»è¯‘äº§å“æè¿°...")
        self.translated_description = self.translate_text(self.description)
        
        print(f"[DEBUG] äº§å“ {name} åˆå§‹åŒ–å®Œæˆ\n")

    def fetch_og_image_url(self) -> str:
        """è·å–äº§å“çš„Open Graphå›¾ç‰‡URL"""
        print(f"æ­£åœ¨è·å–URL: {self.url}")  # æ‰“å°æ­£åœ¨è¯·æ±‚çš„URL
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
        
        # æ·»åŠ éšæœºå»¶è¿Ÿ
        random_delay(2, 5)
        
        try:
            response = requests.get(self.url, headers=headers, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] è¯·æ±‚å¤±è´¥: {e}")
            return ""
        print(f"è¯·æ±‚çŠ¶æ€ç : {response.status_code}")  # æ‰“å°è¯·æ±‚çŠ¶æ€ç 
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # æŸ¥æ‰¾og:image metaæ ‡ç­¾
            og_image = soup.find("meta", property="og:image")
            if og_image:
                print(f"æ‰¾åˆ° og:image æ ‡ç­¾: {og_image}") # æ‰“å° og:image æ ‡ç­¾å†…å®¹
                return og_image["content"]
            # å¤‡ç”¨:æŸ¥æ‰¾twitter:image metaæ ‡ç­¾
            twitter_image = soup.find("meta", name="twitter:image")
            if twitter_image:
                print(f"æ‰¾åˆ° twitter:image æ ‡ç­¾: {twitter_image}") # æ‰“å° twitter:image æ ‡ç­¾å†…å®¹
                return twitter_image["content"]
        print("æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ URL") # æ‰“å°æœªæ‰¾åˆ°å›¾ç‰‡ URL çš„æ¶ˆæ¯
        return ""

    def generate_keywords(self) -> str:
        """ç”Ÿæˆäº§å“çš„å…³é”®è¯ï¼Œæ˜¾ç¤ºåœ¨ä¸€è¡Œï¼Œç”¨é€—å·åˆ†éš”"""
        prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆ3ä¸ªé€‚åˆçš„ä¸­æ–‡å…³é”®è¯ï¼Œç”¨è‹±æ–‡é€—å·åˆ†éš”å¼€ï¼š\n\näº§å“åç§°ï¼š{self.name}\n\næ ‡è¯­ï¼š{self.tagline}\n\næè¿°ï¼š{self.description}"
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                keywords = call_gemini_api(prompt, model="gemini-2.0-flash-exp")
                if keywords:
                    if ',' not in keywords:
                        keywords = ', '.join(keywords.split())
                    time.sleep(random.uniform(5, 8))  # éšæœºç­‰å¾…5-8ç§’
                    return keywords
                else:
                    print(f"APIè¿”å›ç©ºå“åº”ï¼Œå°è¯•é‡è¯• {attempt + 1}/{max_retries}")
            except Exception as e:
                print(f"ç”Ÿæˆå…³é”®è¯æ—¶å‘ç”Ÿé”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(8, 12))  # åœ¨é‡è¯•ä¹‹å‰éšæœºç­‰å¾…8-12ç§’
                else:
                    return "æ— å…³é”®è¯"
        
        return "æ— å…³é”®è¯"

    def translate_text(self, text: str) -> str:
        """ä½¿ç”¨Google Geminiç¿»è¯‘æ–‡æœ¬å†…å®¹"""
        prompt = f"å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ã€‚\n\n{text}"
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                translated_text = call_gemini_api(prompt, model="gemini-2.0-flash-exp")
                if translated_text:
                    time.sleep(5)  # åœ¨APIè°ƒç”¨åç­‰å¾…5ç§’
                    return translated_text
                else:
                    print(f"APIè¿”å›ç©ºå“åº”ï¼Œå°è¯•é‡è¯• {attempt + 1}/{max_retries}")
            except Exception as e:
                print(f"ç¿»è¯‘æ–‡æœ¬æ—¶å‘ç”Ÿé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(8, 12))  # åœ¨é‡è¯•ä¹‹å‰éšæœºç­‰å¾…8-12ç§’
                else:
                    return text  # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
        
        return text

    def convert_to_beijing_time(self, utc_time_str: str) -> str:
        """å°†UTCæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = utc_time.replace(tzinfo=pytz.utc).astimezone(beijing_tz)
        return beijing_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %p%I:%M (åŒ—äº¬æ—¶é—´)')

    def to_markdown(self, rank: int) -> str:
        """è¿”å›äº§å“æ•°æ®çš„Markdownæ ¼å¼"""
        og_image_markdown = f"![{self.name}]({self.og_image_url})"
        return (
            f"## [{rank}. {self.name}]({self.url})  \n"
            f"{og_image_markdown}  \n\n"
            f"**æ ‡è¯­**ï¼š{self.translated_tagline}  \n"
            f"**ä»‹ç»**ï¼š{self.translated_description}  \n"
            f"**ç¥¨æ•°**: ğŸ”º{self.votes_count}  \n"
            f"**å…³é”®è¯**ï¼š{self.keyword}  \n"
            f"**å‘å¸ƒæ—¶é—´**ï¼š{self.created_at}  \n\n"
            #f"**äº§å“ç½‘ç«™**: [ç«‹å³è®¿é—®]({self.website})  \n"
            #f"**Product Hunt**: [View on Product Hunt]({self.url})\n\n"                                  
            #f"**æ˜¯å¦ç²¾é€‰**ï¼š{self.featured} \n"           
            f"---\n\n"
        )

def get_producthunt_token():
    """ä½¿ç”¨ developer token è¿›è¡Œè®¤è¯"""
    token = os.getenv('PRODUCTHUNT_DEVELOPER_TOKEN')
    print(f"token is {token};")
    if not token:
        raise Exception("Product Hunt developer token not found in environment variables")
    return token

def get_session_headers() -> Dict[str, str]:
    """è·å–æ¨¡æ‹Ÿæµè§ˆå™¨çš„è¯·æ±‚å¤´"""
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.1 Safari/605.1.15"
    ]
    
    return {
        "Accept": "application/json, text/plain, */*",
        "Accept-Encoding": "gzip, deflate, br",
        "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
        "Authorization": f"Bearer {get_producthunt_token()}",
        "Content-Type": "application/json",
        "User-Agent": random.choice(user_agents),
        "Origin": "https://producthunt.com",
        "Referer": "https://producthunt.com/",
        "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        "Sec-Ch-Ua-Mobile": "?0",
        "Sec-Ch-Ua-Platform": '"Windows"',
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-site",
        "Connection": "keep-alive"
    }

def create_session_with_retry() -> requests.Session:
    """åˆ›å»ºå¸¦æœ‰é‡è¯•ç­–ç•¥çš„Session"""
    session = requests.Session()
    
    # è®¾ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[403, 429, 500, 502, 503, 504],
        respect_retry_after_header=True
    )
    
    # è®¾ç½®é€‚é…å™¨
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    return session

def random_delay(min_seconds: float = 3, max_seconds: float = 8) -> None:
    """éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«è¯†åˆ«ä¸ºæœºå™¨äºº"""
    delay = random.uniform(min_seconds, max_seconds)
    print(f"[DEBUG] ç­‰å¾… {delay:.2f} ç§’...")
    time.sleep(delay)

def retry_with_backoff(func, max_retries: int = 3, base_delay: float = 5):
    """å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                
                # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ï¼‰
                delay = base_delay * (2 ** attempt) + random.uniform(0, 2)
                print(f"[DEBUG] è¯·æ±‚å¤±è´¥ï¼Œ{delay:.2f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}): {e}")
                time.sleep(delay)
        
    return wrapper

def fetch_product_hunt_data() -> List[Product]:
    """ä»Product Huntè·å–å‰ä¸€å¤©çš„Top 24æ•°æ®"""
    print("[DEBUG] åˆå§‹åŒ–Sessionå’Œè¯·æ±‚å¤´...")
    session = create_session_with_retry()
    headers = get_session_headers()
    
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    url = "https://api.producthunt.com/v2/api/graphql"
    
    base_query = """
    {
      posts(order: VOTES, postedAfter: "%sT00:00:00Z", postedBefore: "%sT23:59:59Z", after: "%s") {
        nodes {
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
        }
        pageInfo {
          hasNextPage
          endCursor
        }
      }
    }
    """

    def make_graphql_request(cursor: str) -> Dict[str, Any]:
        """å‘é€GraphQLè¯·æ±‚"""
        query = base_query % (date_str, date_str, cursor)
        print(f"[DEBUG] å‘é€è¯·æ±‚åˆ°Product Hunt API...")
        
        try:
            response = session.post(url, headers=headers, json={"query": query}, timeout=30)
            
            print(f"[DEBUG] å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"[DEBUG] å“åº”å¤´: {dict(response.headers)}")
            
            # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '')
            if 'application/json' not in content_type:
                print(f"[DEBUG] è­¦å‘Š: å“åº”ä¸æ˜¯JSONæ ¼å¼ï¼ŒContent-Type: {content_type}")
                print(f"[DEBUG] å“åº”å†…å®¹å‰500å­—ç¬¦: {response.text[:500]}")
                
            if response.status_code == 403:
                print(f"[DEBUG] æ”¶åˆ°403é”™è¯¯ï¼Œå¯èƒ½è§¦å‘äº†Cloudflareé˜²æŠ¤")
                if "cf-browser-verification" in response.text or "challenge" in response.text.lower():
                    print("[DEBUG] æ£€æµ‹åˆ°CloudflareæŒ‘æˆ˜é¡µé¢ï¼Œéœ€è¦æ›´é«˜çº§çš„ç»•è¿‡æ–¹æ³•")
                    raise Exception("Cloudflare challenge detected")
                
            response.raise_for_status()
            
            # å°è¯•è§£æJSON
            try:
                return response.json()
            except json.JSONDecodeError as e:
                print(f"[DEBUG] JSONè§£æé”™è¯¯: {e}")
                print(f"[DEBUG] å“åº”å†…å®¹: {response.text}")
                raise
                
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] è¯·æ±‚å¼‚å¸¸: {e}")
            raise

    all_posts = []
    has_next_page = True
    cursor = ""
    retry_count = 0
    max_retries = 3

    while has_next_page and len(all_posts) < 24:
        try:
            # åœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æˆ–åç»­è¯·æ±‚ä¹‹é—´æ·»åŠ éšæœºå»¶è¿Ÿ
            if cursor != "":
                random_delay(5, 10)
            
            data = make_graphql_request(cursor)
            posts = data['data']['posts']['nodes']
            all_posts.extend(posts)

            has_next_page = data['data']['posts']['pageInfo']['hasNextPage']
            cursor = data['data']['posts']['pageInfo']['endCursor']
            
            print(f"[DEBUG] å·²è·å– {len(posts)} ä¸ªäº§å“ï¼Œæ€»è®¡ {len(all_posts)} ä¸ª")
            
            # é‡ç½®é‡è¯•è®¡æ•°
            retry_count = 0
            
        except Exception as e:
            retry_count += 1
            print(f"[DEBUG] è·å–æ•°æ®å¤±è´¥ (å°è¯• {retry_count}/{max_retries}): {e}")
            
            if retry_count >= max_retries:
                print("[DEBUG] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç»ˆæ­¢è¯·æ±‚")
                break
            
            # æŒ‡æ•°é€€é¿
            delay = 10 * (2 ** (retry_count - 1)) + random.uniform(0, 5)
            print(f"[DEBUG] {delay:.2f} ç§’åé‡è¯•...")
            time.sleep(delay)

    # åªä¿ç•™å‰24ä¸ªäº§å“
    sorted_posts = sorted(all_posts, key=lambda x: x['votesCount'], reverse=True)[:24]
    print(f"[DEBUG] æœ€ç»ˆé€‰å–å‰24ä¸ªäº§å“")
    
    # å…³é—­session
    session.close()
    
    return [Product(**post) for post in sorted_posts]

def generate_markdown(products, date_str):
    """ç”ŸæˆMarkdownå†…å®¹å¹¶ä¿å­˜åˆ°dataç›®å½•"""
    # è·å–ä»Šå¤©çš„æ—¥æœŸå¹¶æ ¼å¼åŒ–
    today = datetime.now(timezone.utc)
    date_today = today.strftime('%Y-%m-%d')

    markdown_content = f"# PHä»Šæ—¥çƒ­æ¦œ | {date_today}\n\n"
    for rank, product in enumerate(products, 1):
        markdown_content += product.to_markdown(rank)

    # ç¡®ä¿ data ç›®å½•å­˜åœ¨
    os.makedirs('data', exist_ok=True)

    # ä¿®æ”¹æ–‡ä»¶ä¿å­˜è·¯å¾„åˆ° data ç›®å½•
    file_name = f"data/producthunt-daily-{date_today}.md"
    
    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†ç›–
    with open(file_name, 'w', encoding='utf-8') as file:
        file.write(markdown_content)
    print(f"æ–‡ä»¶ {file_name} ç”ŸæˆæˆåŠŸå¹¶å·²è¦†ç›–ã€‚")


def main():
    print("\n[DEBUG] ç¨‹åºå¼€å§‹è¿è¡Œ...")
    print(f"[DEBUG] Pythonç‰ˆæœ¬: {os.sys.version}")
    print(f"[DEBUG] requestsç‰ˆæœ¬: {requests.__version__}")
    
    # è·å–æ˜¨å¤©çš„æ—¥æœŸå¹¶æ ¼å¼åŒ–
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    print(f"[DEBUG] å¤„ç†æ—¥æœŸ: {date_str}")

    # è·å–Product Huntæ•°æ®
    print("[DEBUG] å¼€å§‹è·å–Product Huntæ•°æ®...")
    try:
        products = fetch_product_hunt_data()
        print(f"[DEBUG] æˆåŠŸè·å–{len(products)}ä¸ªäº§å“æ•°æ®")
        
        if not products:
            print("[DEBUG] è­¦å‘Š: æ²¡æœ‰è·å–åˆ°ä»»ä½•äº§å“æ•°æ®")
            return
            
    except Exception as e:
        print(f"[DEBUG] è·å–Product Huntæ•°æ®å¤±è´¥: {e}")
        print("[DEBUG] ç¨‹åºå¼‚å¸¸ç»ˆæ­¢")
        raise

    # ç”ŸæˆMarkdownæ–‡ä»¶
    print("[DEBUG] å¼€å§‹ç”ŸæˆMarkdownæ–‡ä»¶...")
    generate_markdown(products, date_str)
    print("[DEBUG] ç¨‹åºè¿è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
