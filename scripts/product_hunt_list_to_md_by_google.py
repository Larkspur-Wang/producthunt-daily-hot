import os
# from dotenv import load_dotenv
try:
    import cloudscraper
except ImportError:
    cloudscraper = None
import requests
from datetime import datetime, timedelta, timezone
from bs4 import BeautifulSoup
import pytz
import time
import random
import json
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from typing import Optional, List, Dict, Any

# åŠ è½½ .env æ–‡ä»¶
# load_dotenv()

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"

producthunt_client_id = os.getenv('PRODUCTHUNT_CLIENT_ID')
producthunt_client_secret = os.getenv('PRODUCTHUNT_CLIENT_SECRET')

def call_gemini_api(prompt: str, model: str = "gemini-2.0-flash-exp", temperature: float = 0.8) -> str:
    """è°ƒç”¨Google Gemini API"""
    print(f"\n[DEBUG] æ­£åœ¨è°ƒç”¨Gemini APIï¼Œæ¨¡å‹ï¼š{model}")
    try:
        if not GOOGLE_API_KEY:
            raise ValueError("GOOGLE_API_KEY not found in environment variables")
            
        url = f"{GEMINI_API_BASE}/{model}:generateContent?key={GOOGLE_API_KEY}"
        headers = {'Content-Type': 'application/json'}
        
        data = {
            "contents": [{
                "parts":[{"text": prompt}]
            }],
            "generationConfig": {
                "temperature": temperature,
                "topK": 40,
                "topP": 0.95,
            }
        }
        
        print(f"[DEBUG] å‘é€APIè¯·æ±‚...")
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'candidates' in result and len(result['candidates']) > 0:
            print(f"[DEBUG] APIè°ƒç”¨æˆåŠŸ")
            return result['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            print(f"[DEBUG] APIè¿”å›ç»“æœä¸ºç©º")
            return ""
    except Exception as e:
        print(f"[DEBUG] APIè°ƒç”¨é”™è¯¯: {e}")
        return ""

class Product:
    def __init__(self, id: str, name: str, tagline: str, description: str, votesCount: int, createdAt: str, featuredAt: str, website: str, url: str, **kwargs):
        print(f"\n[DEBUG] æ­£åœ¨åˆå§‹åŒ–äº§å“: {name}")
        self.name = name
        self.tagline = tagline
        self.description = description
        self.votes_count = votesCount
        self.created_at = self.convert_to_beijing_time(createdAt)
        self.featured = "æ˜¯" if featuredAt else "å¦"
        self.website = website
        self.url = url
        
        print(f"[DEBUG] è·å–äº§å“å›¾ç‰‡URL...")
        self.og_image_url = self.fetch_og_image_url()
        
        print(f"[DEBUG] ç”Ÿæˆäº§å“å…³é”®è¯...")
        self.keyword = self.generate_keywords()
        
        print(f"[DEBUG] ç¿»è¯‘äº§å“æ ‡è¯­...")
        self.translated_tagline = self.translate_text(self.tagline)
        
        print(f"[DEBUG] ç¿»è¯‘äº§å“æè¿°...")
        self.translated_description = self.translate_text(self.description)
        
        print(f"[DEBUG] äº§å“ {name} åˆå§‹åŒ–å®Œæˆ\n")

    def fetch_og_image_url(self) -> str:
        """è·å–äº§å“çš„Open Graphå›¾ç‰‡URL"""
        print(f"æ­£åœ¨è·å–URL: {self.url}")  # æ‰“å°æ­£åœ¨è¯·æ±‚çš„URL
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
        
        # æ·»åŠ éšæœºå»¶è¿Ÿ
        random_delay(2, 5)
        
        try:
            response = requests.get(self.url, headers=headers, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] è¯·æ±‚å¤±è´¥: {e}")
            return ""
        print(f"è¯·æ±‚çŠ¶æ€ç : {response.status_code}")  # æ‰“å°è¯·æ±‚çŠ¶æ€ç 
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # æŸ¥æ‰¾og:image metaæ ‡ç­¾
            og_image = soup.find("meta", property="og:image")
            if og_image:
                print(f"æ‰¾åˆ° og:image æ ‡ç­¾: {og_image}") # æ‰“å° og:image æ ‡ç­¾å†…å®¹
                return og_image["content"]
            # å¤‡ç”¨:æŸ¥æ‰¾twitter:image metaæ ‡ç­¾
            twitter_image = soup.find("meta", name="twitter:image")
            if twitter_image:
                print(f"æ‰¾åˆ° twitter:image æ ‡ç­¾: {twitter_image}") # æ‰“å° twitter:image æ ‡ç­¾å†…å®¹
                return twitter_image["content"]
        print("æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ URL") # æ‰“å°æœªæ‰¾åˆ°å›¾ç‰‡ URL çš„æ¶ˆæ¯
        return ""

    def generate_keywords(self) -> str:
        """ç”Ÿæˆäº§å“çš„å…³é”®è¯ï¼Œæ˜¾ç¤ºåœ¨ä¸€è¡Œï¼Œç”¨é€—å·åˆ†éš”"""
        prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆ3ä¸ªé€‚åˆçš„ä¸­æ–‡å…³é”®è¯ï¼Œç”¨è‹±æ–‡é€—å·åˆ†éš”å¼€ï¼š\n\näº§å“åç§°ï¼š{self.name}\n\næ ‡è¯­ï¼š{self.tagline}\n\næè¿°ï¼š{self.description}"
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                keywords = call_gemini_api(prompt, model="gemini-2.0-flash-exp")
                if keywords:
                    if ',' not in keywords:
                        keywords = ', '.join(keywords.split())
                    time.sleep(random.uniform(5, 8))  # éšæœºç­‰å¾…5-8ç§’
                    return keywords
                else:
                    print(f"APIè¿”å›ç©ºå“åº”ï¼Œå°è¯•é‡è¯• {attempt + 1}/{max_retries}")
            except Exception as e:
                print(f"ç”Ÿæˆå…³é”®è¯æ—¶å‘ç”Ÿé”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(8, 12))  # åœ¨é‡è¯•ä¹‹å‰éšæœºç­‰å¾…8-12ç§’
                else:
                    return "æ— å…³é”®è¯"
        
        return "æ— å…³é”®è¯"

    def translate_text(self, text: str) -> str:
        """ä½¿ç”¨Google Geminiç¿»è¯‘æ–‡æœ¬å†…å®¹"""
        prompt = f"å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ã€‚\n\n{text}"
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                translated_text = call_gemini_api(prompt, model="gemini-2.0-flash-exp")
                if translated_text:
                    time.sleep(5)  # åœ¨APIè°ƒç”¨åç­‰å¾…5ç§’
                    return translated_text
                else:
                    print(f"APIè¿”å›ç©ºå“åº”ï¼Œå°è¯•é‡è¯• {attempt + 1}/{max_retries}")
            except Exception as e:
                print(f"ç¿»è¯‘æ–‡æœ¬æ—¶å‘ç”Ÿé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(8, 12))  # åœ¨é‡è¯•ä¹‹å‰éšæœºç­‰å¾…8-12ç§’
                else:
                    return text  # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
        
        return text

    def convert_to_beijing_time(self, utc_time_str: str) -> str:
        """å°†UTCæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = utc_time.replace(tzinfo=pytz.utc).astimezone(beijing_tz)
        return beijing_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %p%I:%M (åŒ—äº¬æ—¶é—´)')

    def to_markdown(self, rank: int) -> str:
        """è¿”å›äº§å“æ•°æ®çš„Markdownæ ¼å¼"""
        og_image_markdown = f"![{self.name}]({self.og_image_url})"
        return (
            f"## [{rank}. {self.name}]({self.url})  \n"
            f"{og_image_markdown}  \n\n"
            f"**æ ‡è¯­**ï¼š{self.translated_tagline}  \n"
            f"**ä»‹ç»**ï¼š{self.translated_description}  \n"
            f"**ç¥¨æ•°**: ğŸ”º{self.votes_count}  \n"
            f"**å…³é”®è¯**ï¼š{self.keyword}  \n"
            f"**å‘å¸ƒæ—¶é—´**ï¼š{self.created_at}  \n\n"
            #f"**äº§å“ç½‘ç«™**: [ç«‹å³è®¿é—®]({self.website})  \n"
            #f"**Product Hunt**: [View on Product Hunt]({self.url})\n\n"                                  
            #f"**æ˜¯å¦ç²¾é€‰**ï¼š{self.featured} \n"           
            f"---\n\n"
        )

def get_producthunt_token():
    """è·å–Product Hunt API token"""
    # é¦–å…ˆå°è¯•ä½¿ç”¨developer token
    token = os.getenv('PRODUCTHUNT_DEVELOPER_TOKEN')
    print(f"token is {'***' if token else 'None'};")
    
    if not token:
        # å¦‚æœæ²¡æœ‰developer tokenï¼Œå°è¯•ä½¿ç”¨OAuth
        client_id = os.getenv('PRODUCTHUNT_CLIENT_ID')
        client_secret = os.getenv('PRODUCTHUNT_CLIENT_SECRET')
        
        if not client_id or not client_secret:
            raise Exception("Neither Product Hunt developer token nor OAuth credentials found in environment variables")
        
        # è·å–OAuth token
        print("[DEBUG] å°è¯•ä½¿ç”¨OAuthè®¤è¯...")
        try:
            auth_url = "https://api.producthunt.com/v2/oauth/token"
            auth_data = {
                "client_id": client_id,
                "client_secret": client_secret,
                "grant_type": "client_credentials"
            }
            
            response = requests.post(auth_url, json=auth_data, timeout=30)
            response.raise_for_status()
            
            auth_result = response.json()
            token = auth_result.get('access_token')
            
            if not token:
                raise Exception("Failed to get access token from OAuth")
                
            print("[DEBUG] OAuthè®¤è¯æˆåŠŸ")
            return token
            
        except Exception as e:
            print(f"[DEBUG] OAuthè®¤è¯å¤±è´¥: {e}")
            raise
    
    return token

def get_session_headers() -> Dict[str, str]:
    """è·å–æ¨¡æ‹Ÿæµè§ˆå™¨çš„è¯·æ±‚å¤´ - ç®€åŒ–ç‰ˆæœ¬"""
    user_agents = [
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    ]
    
    return {
        "Accept": "application/json",
        "Accept-Language": "en-US,en;q=0.9",
        "Authorization": f"Bearer {get_producthunt_token()}",
        "Content-Type": "application/json",
        "User-Agent": random.choice(user_agents),
        "Origin": "https://producthunt.com",
        "Referer": "https://producthunt.com/"
    }

def create_session_with_retry() -> requests.Session:
    """åˆ›å»ºå¸¦æœ‰é‡è¯•ç­–ç•¥çš„Session"""
    # ä¼˜å…ˆä½¿ç”¨cloudscraper
    if cloudscraper is not None:
        print("[DEBUG] ä½¿ç”¨cloudscraperåˆ›å»ºsession...")
        try:
            # åˆ›å»ºcloudscraperå®ä¾‹
            scraper = cloudscraper.create_scraper()
            
            # è®¾ç½®é‡è¯•ç­–ç•¥
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[403, 429, 500, 502, 503, 504],
                respect_retry_after_header=True
            )
            
            # è®¾ç½®é€‚é…å™¨
            adapter = HTTPAdapter(max_retries=retry_strategy)
            scraper.mount("https://", adapter)
            scraper.mount("http://", adapter)
            
            return scraper
        except Exception as e:
            print(f"[DEBUG] cloudscraperåˆ›å»ºå¤±è´¥ï¼Œå›é€€åˆ°requests: {e}")
    
    # å›é€€åˆ°æ™®é€šrequests
    print("[DEBUG] ä½¿ç”¨requestsåˆ›å»ºsession...")
    session = requests.Session()
    
    # è®¾ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[403, 429, 500, 502, 503, 504],
        respect_retry_after_header=True
    )
    
    # è®¾ç½®é€‚é…å™¨
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    return session

def random_delay(min_seconds: float = 3, max_seconds: float = 8) -> None:
    """éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«è¯†åˆ«ä¸ºæœºå™¨äºº"""
    delay = random.uniform(min_seconds, max_seconds)
    print(f"[DEBUG] ç­‰å¾… {delay:.2f} ç§’...")
    time.sleep(delay)

def retry_with_backoff(func, max_retries: int = 3, base_delay: float = 5):
    """å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                
                # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ï¼‰
                delay = base_delay * (2 ** attempt) + random.uniform(0, 2)
                print(f"[DEBUG] è¯·æ±‚å¤±è´¥ï¼Œ{delay:.2f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}): {e}")
                time.sleep(delay)
        
    return wrapper

def fetch_product_hunt_data_simple() -> List[Product]:
    """ç®€åŒ–çš„Product Huntæ•°æ®è·å– - åŸºäºæµ‹è¯•æˆåŠŸçš„ç‰ˆæœ¬"""
    print("[DEBUG] ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è·å–Product Huntæ•°æ®...")
    
    # ä½¿ç”¨æœ‰æ•ˆçš„token
    token = os.getenv('PRODUCTHUNT_DEVELOPER_TOKEN')
    if not token:
        raise Exception("PRODUCTHUNT_DEVELOPER_TOKEN not found in environment variables")
    
    print(f"[DEBUG] Token: {'***' if token else 'None'}")
    
    # APIç«¯ç‚¹
    url = "https://api.producthunt.com/v2/api/graphql"
    
    # è®¡ç®—æ˜¨å¤©çš„æ—¥æœŸ
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    
    print(f"[DEBUG] è·å–æ—¥æœŸ: {date_str}")
    
    # ä½¿ç”¨æµ‹è¯•æˆåŠŸçš„headers
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "Origin": "https://producthunt.com",
        "Referer": "https://producthunt.com/",
        "Connection": "keep-alive"
    }
    
    # ç®€åŒ–çš„æŸ¥è¯¢ - ç›´æ¥è·å–å‰24ä¸ª
    query = f"""
    {{
      posts(first: 24, order: VOTES, postedAfter: "{date_str}T00:00:00Z", postedBefore: "{date_str}T23:59:59Z") {{
        nodes {{
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
        }}
      }}
    }}
    """
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"[DEBUG] å‘é€APIè¯·æ±‚ (å°è¯• {attempt + 1}/{max_retries})...")
            
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            if attempt > 0:
                delay = random.uniform(5, 15)
                print(f"[DEBUG] ç­‰å¾… {delay:.1f} ç§’...")
                time.sleep(delay)
            
            response = requests.post(url, headers=headers, json={"query": query}, timeout=30)
            
            print(f"[DEBUG] çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                
                if 'errors' in data:
                    print(f"[ERROR] APIé”™è¯¯: {data['errors']}")
                    if attempt == max_retries - 1:
                        return []
                    continue
                
                posts = data.get('data', {}).get('posts', {}).get('nodes', [])
                print(f"[DEBUG] æˆåŠŸè·å– {len(posts)} ä¸ªå¸–å­")
                
                # æŒ‰ç¥¨æ•°æ’åº
                posts.sort(key=lambda x: x['votesCount'], reverse=True)
                
                return posts[:24]  # ç¡®ä¿æœ€å¤š24ä¸ª
                
            elif response.status_code == 403:
                print(f"[DEBUG] æ”¶åˆ°403é”™è¯¯ï¼Œå¯èƒ½æ˜¯Cloudflareé˜²æŠ¤")
                if attempt == max_retries - 1:
                    return []
            else:
                print(f"[ERROR] è¯·æ±‚å¤±è´¥: {response.status_code}")
                if attempt == max_retries - 1:
                    return []
                
        except Exception as e:
            print(f"[ERROR] è¯·æ±‚å¼‚å¸¸: {e}")
            if attempt == max_retries - 1:
                return []
    
    return []

def fetch_product_hunt_data() -> List[Product]:
    """ä»Product Huntè·å–å‰ä¸€å¤©çš„Top 24æ•°æ®"""
    print("[DEBUG] åˆå§‹åŒ–Sessionå’Œè¯·æ±‚å¤´...")
    session = create_session_with_retry()
    headers = get_session_headers()
    
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    
    # å°è¯•ä¸åŒçš„APIç«¯ç‚¹
    api_endpoints = [
        "https://api.producthunt.com/v2/api/graphql",
        "https://producthunt.com/api/graphql"
    ]
    
    last_exception = None
    
    base_query = """
    {
      posts(order: VOTES, postedAfter: "%sT00:00:00Z", postedBefore: "%sT23:59:59Z", after: "%s") {
        nodes {
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
        }
        pageInfo {
          hasNextPage
          endCursor
        }
      }
    }
    """
    
    # å¤‡ç”¨æŸ¥è¯¢ - æ›´ç®€å•çš„ç‰ˆæœ¬
    simple_query = """
    {
      posts(first: 24, order: VOTES, postedAfter: "%sT00:00:00Z", postedBefore: "%sT23:59:59Z") {
        nodes {
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
        }
      }
    }
    """

    def make_graphql_request(cursor: str, api_url: str, use_simple_query: bool = False) -> Dict[str, Any]:
        """å‘é€GraphQLè¯·æ±‚"""
        # æ ¹æ®å‚æ•°é€‰æ‹©æŸ¥è¯¢ç±»å‹
        if use_simple_query:
            query = simple_query % (date_str, date_str)
            print(f"[DEBUG] ä½¿ç”¨ç®€å•æŸ¥è¯¢...")
        else:
            query = base_query % (date_str, date_str, cursor)
            print(f"[DEBUG] ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢...")
            
        print(f"[DEBUG] å‘é€è¯·æ±‚åˆ°Product Hunt API...")
        
        # å°è¯•ä¸åŒçš„è¯·æ±‚æ–¹å¼
        methods = [
            # æ–¹æ³•1: POST with JSON
            lambda: session.post(api_url, headers=headers, json={"query": query}, timeout=30),
            # æ–¹æ³•2: POST with form data
            lambda: session.post(api_url, headers={**headers, "Content-Type": "application/x-www-form-urlencoded"}, 
                               data=f"query={query}", timeout=30)
        ]
        
        last_exception = None
        
        for i, method in enumerate(methods):
            try:
                print(f"[DEBUG] å°è¯•è¯·æ±‚æ–¹æ³• {i+1}...")
                response = method()
                
                print(f"[DEBUG] å“åº”çŠ¶æ€ç : {response.status_code}")
                
                # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '')
                if 'application/json' not in content_type:
                    print(f"[DEBUG] è­¦å‘Š: å“åº”ä¸æ˜¯JSONæ ¼å¼ï¼ŒContent-Type: {content_type}")
                    print(f"[DEBUG] å“åº”å†…å®¹å‰500å­—ç¬¦: {response.text[:500]}")
                    
                if response.status_code == 403:
                    print(f"[DEBUG] æ”¶åˆ°403é”™è¯¯ï¼Œå¯èƒ½è§¦å‘äº†Cloudflareé˜²æŠ¤")
                    if "cf-browser-verification" in response.text or "challenge" in response.text.lower():
                        print("[DEBUG] æ£€æµ‹åˆ°CloudflareæŒ‘æˆ˜é¡µé¢")
                    last_exception = Exception(f"403 Forbidden: {response.text[:200]}")
                    continue
                
                response.raise_for_status()
                
                # å°è¯•è§£æJSON
                try:
                    return response.json()
                except json.JSONDecodeError as e:
                    print(f"[DEBUG] JSONè§£æé”™è¯¯: {e}")
                    print(f"[DEBUG] å“åº”å†…å®¹: {response.text}")
                    last_exception = e
                    continue
                    
            except requests.exceptions.RequestException as e:
                print(f"[DEBUG] è¯·æ±‚å¼‚å¸¸: {e}")
                last_exception = e
                continue
        
        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
        raise last_exception or Exception("All request methods failed")

    # å°è¯•æ¯ä¸ªAPIç«¯ç‚¹
    for api_url in api_endpoints:
        try:
            print(f"\n[DEBUG] === å°è¯•APIç«¯ç‚¹: {api_url} ===")
            url = api_url
            
            all_posts = []
            has_next_page = True
            cursor = ""
            retry_count = 0
            max_retries = 3

            # é¦–å…ˆå°è¯•ç®€å•æŸ¥è¯¢ï¼ˆä¸€æ¬¡æ€§è·å–24ä¸ªï¼‰
            try:
                print("[DEBUG] å°è¯•ç®€å•æŸ¥è¯¢...")
                data = make_graphql_request("", api_url, use_simple_query=True)
                posts = data['data']['posts']['nodes']
                all_posts.extend(posts)
                print(f"[DEBUG] ç®€å•æŸ¥è¯¢æˆåŠŸè·å– {len(posts)} ä¸ªäº§å“")
                
                # å¦‚æœç®€å•æŸ¥è¯¢æˆåŠŸï¼Œç›´æ¥è·³è¿‡åˆ†é¡µ
                if all_posts:
                    sorted_posts = sorted(all_posts, key=lambda x: x['votesCount'], reverse=True)[:24]
                    print(f"[DEBUG] æœ€ç»ˆé€‰å–å‰24ä¸ªäº§å“")
                    
                    # å…³é—­session
                    session.close()
                    
                    return [Product(**post) for post in sorted_posts]
                    
            except Exception as e:
                print(f"[DEBUG] ç®€å•æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•åˆ†é¡µæŸ¥è¯¢: {e}")
                
                # å›é€€åˆ°åˆ†é¡µæŸ¥è¯¢
                while has_next_page and len(all_posts) < 24:
                    try:
                        # åœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æˆ–åç»­è¯·æ±‚ä¹‹é—´æ·»åŠ éšæœºå»¶è¿Ÿ
                        if cursor != "":
                            random_delay(5, 10)
                        
                        data = make_graphql_request(cursor, api_url, use_simple_query=False)
                        posts = data['data']['posts']['nodes']
                        all_posts.extend(posts)

                        has_next_page = data['data']['posts']['pageInfo']['hasNextPage']
                        cursor = data['data']['posts']['pageInfo']['endCursor']
                        
                        print(f"[DEBUG] å·²è·å– {len(posts)} ä¸ªäº§å“ï¼Œæ€»è®¡ {len(all_posts)} ä¸ª")
                        
                        # é‡ç½®é‡è¯•è®¡æ•°
                        retry_count = 0
                        
                    except Exception as e:
                        retry_count += 1
                        print(f"[DEBUG] è·å–æ•°æ®å¤±è´¥ (å°è¯• {retry_count}/{max_retries}): {e}")
                        
                        if retry_count >= max_retries:
                            print("[DEBUG] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå°è¯•ä¸‹ä¸€ä¸ªAPIç«¯ç‚¹")
                            break
                        
                        # æŒ‡æ•°é€€é¿
                        delay = 10 * (2 ** (retry_count - 1)) + random.uniform(0, 5)
                        print(f"[DEBUG] {delay:.2f} ç§’åé‡è¯•...")
                        time.sleep(delay)
            
            # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ï¼Œè¿”å›ç»“æœ
            if all_posts:
                sorted_posts = sorted(all_posts, key=lambda x: x['votesCount'], reverse=True)[:24]
                print(f"[DEBUG] æœ€ç»ˆé€‰å–å‰24ä¸ªäº§å“")
                
                # å…³é—­session
                session.close()
                
                return [Product(**post) for post in sorted_posts]
                
        except Exception as e:
            print(f"[DEBUG] APIç«¯ç‚¹ {api_url} å¤±è´¥: {e}")
            last_exception = e
            continue
    
    # æ‰€æœ‰APIç«¯ç‚¹éƒ½å¤±è´¥äº†
    print("[DEBUG] æ‰€æœ‰APIç«¯ç‚¹éƒ½å¤±è´¥äº†")
    session.close()
    raise last_exception or Exception("æ‰€æœ‰APIç«¯ç‚¹éƒ½å¤±è´¥äº†")

def generate_markdown(products, date_str):
    """ç”ŸæˆMarkdownå†…å®¹å¹¶ä¿å­˜åˆ°dataç›®å½•"""
    # è·å–ä»Šå¤©çš„æ—¥æœŸå¹¶æ ¼å¼åŒ–
    today = datetime.now(timezone.utc)
    date_today = today.strftime('%Y-%m-%d')

    markdown_content = f"# PHä»Šæ—¥çƒ­æ¦œ | {date_today}\n\n"
    for rank, product in enumerate(products, 1):
        markdown_content += product.to_markdown(rank)

    # ç¡®ä¿ data ç›®å½•å­˜åœ¨
    os.makedirs('data', exist_ok=True)

    # ä¿®æ”¹æ–‡ä»¶ä¿å­˜è·¯å¾„åˆ° data ç›®å½•
    file_name = f"data/producthunt-daily-{date_today}.md"
    
    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†ç›–
    with open(file_name, 'w', encoding='utf-8') as file:
        file.write(markdown_content)
    print(f"æ–‡ä»¶ {file_name} ç”ŸæˆæˆåŠŸå¹¶å·²è¦†ç›–ã€‚")


def main():
    print("\n[DEBUG] ç¨‹åºå¼€å§‹è¿è¡Œ...")
    print(f"[DEBUG] Pythonç‰ˆæœ¬: {os.sys.version}")
    print(f"[DEBUG] requestsç‰ˆæœ¬: {requests.__version__}")
    
    # è·å–æ˜¨å¤©çš„æ—¥æœŸå¹¶æ ¼å¼åŒ–
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    print(f"[DEBUG] å¤„ç†æ—¥æœŸ: {date_str}")

    # è·å–Product Huntæ•°æ®
    print("[DEBUG] å¼€å§‹è·å–Product Huntæ•°æ®...")
    try:
        # é¦–å…ˆå°è¯•ç®€åŒ–ç‰ˆæœ¬
        print("[DEBUG] å°è¯•ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è·å–æ•°æ®...")
        products = fetch_product_hunt_data_simple()
        
        if not products:
            print("[DEBUG] ç®€åŒ–ç‰ˆæœ¬å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å®Œæ•´ç‰ˆæœ¬...")
            products = fetch_product_hunt_data()
        
        print(f"[DEBUG] æˆåŠŸè·å–{len(products)}ä¸ªäº§å“æ•°æ®")
        
        if not products:
            print("[DEBUG] è­¦å‘Š: æ²¡æœ‰è·å–åˆ°ä»»ä½•äº§å“æ•°æ®")
            return
            
    except Exception as e:
        print(f"[DEBUG] è·å–Product Huntæ•°æ®å¤±è´¥: {e}")
        print("[DEBUG] ç¨‹åºå¼‚å¸¸ç»ˆæ­¢")
        raise

    # ç”ŸæˆMarkdownæ–‡ä»¶
    print("[DEBUG] å¼€å§‹ç”ŸæˆMarkdownæ–‡ä»¶...")
    generate_markdown(products, date_str)
    print("[DEBUG] ç¨‹åºè¿è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
